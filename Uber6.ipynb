{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "file_path = 'churnnotclean.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_37144\\1494184677.py:2: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df['last_trip_date'] = pd.to_datetime(df['last_trip_date'], errors='coerce')\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_37144\\1494184677.py:3: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df['signup_date'] = pd.to_datetime(df['signup_date'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# 创建新变量 Duration 和 Surge_interation\n",
    "df['last_trip_date'] = pd.to_datetime(df['last_trip_date'], errors='coerce')\n",
    "df['signup_date'] = pd.to_datetime(df['signup_date'], errors='coerce')\n",
    "\n",
    "# 计算 Duration\n",
    "df['Duration'] = (df['last_trip_date'] - df['signup_date']).dt.days\n",
    "\n",
    "# 计算 Surge_interation\n",
    "df['Surge_interation'] = df['avg_surge'] * df['surge_pct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分离数值型和类别型列\n",
    "numeric_columns = ['avg_rating_by_driver', 'avg_dist', 'avg_surge', 'surge_pct', 'trips_in_first_30_days', 'weekday_pct']  # 根据实际列名填写数值型列\n",
    "category_columns = ['city', 'phone', 'luxury_car_user']  # 根据实际列名填写类别型列\n",
    "\n",
    "# 处理数值型列的缺失值：使用均值填充\n",
    "for column in numeric_columns:\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')  # 将所有数值列转换为数值类型\n",
    "    df[column].fillna(df[column].mean(), inplace=True)\n",
    "\n",
    "# 处理类别型列的缺失值：使用众数填充\n",
    "for column in category_columns:\n",
    "    df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "\n",
    "# 对类别型变量进行标签编码（将字符串转为数值）\n",
    "label_encoder = LabelEncoder()\n",
    "for column in category_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 筛选所需的特征\n",
    "df_filtered = df[['avg_rating_by_driver','city', 'phone', 'luxury_car_user', 'surge_pct','churn','avg_dist','weekday_pct','Duration','Surge_interation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 处理缺失值\n",
    "# df_filtered.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# # 编码类别变量\n",
    "# label_encoder = LabelEncoder()\n",
    "# df_filtered['city'] = label_encoder.fit_transform(df_filtered['city'])\n",
    "# df_filtered['phone'] = label_encoder.fit_transform(df_filtered['phone'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征矩阵 X 和目标向量 y\n",
    "X = df_filtered.drop(columns=['churn'])\n",
    "y = df_filtered['churn']\n",
    "\n",
    "# 数据集划分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 特征标准化\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 将数据重塑为 2D 以适应 Conv1D 层\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 构建CNN模型\n",
    "model = Sequential()\n",
    "model.add(Conv1D(32, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7982 - loss: 0.4420\n",
      "Epoch 2/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8354 - loss: 0.3701\n",
      "Epoch 3/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8419 - loss: 0.3572\n",
      "Epoch 4/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8470 - loss: 0.3480\n",
      "Epoch 5/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8449 - loss: 0.3519\n",
      "Epoch 6/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8486 - loss: 0.3443\n",
      "Epoch 7/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8463 - loss: 0.3462\n",
      "Epoch 8/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8486 - loss: 0.3408\n",
      "Epoch 9/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8525 - loss: 0.3376\n",
      "Epoch 10/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8512 - loss: 0.3368\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# 进行模型预测\n",
    "y_pred_prob = model.predict(X_test).ravel()\n",
    "y_pred_class = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# 评估模型：准确率、分类报告和ROC-AUC分数\n",
    "accuracy = accuracy_score(y_test, y_pred_class)\n",
    "classification_rep = classification_report(y_test, y_pred_class)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8466\n",
      "Classification Report:\\n               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.75      0.82      4720\n",
      "           1       0.81      0.93      0.86      5280\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.86      0.84      0.84     10000\n",
      "weighted avg       0.85      0.85      0.84     10000\n",
      "\n",
      "ROC-AUC: 0.9091\n"
     ]
    }
   ],
   "source": [
    " # 打印评估结果\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print('Classification Report:\\\\n', classification_rep)\n",
    "print(f'ROC-AUC: {roc_auc:.4f}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
